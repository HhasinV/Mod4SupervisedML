{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce3ba69-ece1-4fc7-bfc8-7346b5c98e57",
   "metadata": {},
   "source": [
    "### Quels sont les objectifs\n",
    "Les data scientists √† l'origine de la newsletter souhaitent mieux comprendre le comportement des utilisateurs visitant leur site web. Ils aimeraient savoir s'il est possible de construire un mod√®le pr√©dictif de l'abonnement √† la newsletter, √† partir de quelques informations seulement. Ils envisagent ensuite d'analyser les param√®tres de ce mod√®le afin de mettre en √©vidence les caract√©ristiques pertinentes pour expliquer ce comportement et, √©ventuellement, identifier un nouveau levier d'action pour am√©liorer le taux de conversion de la newsletter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7737c82-5f76-46e0-b507-0c64c9f802d9",
   "metadata": {},
   "source": [
    "### The project can be cut into four steps :\n",
    "\n",
    "- **Part 1 :** make an **EDA** and the **preprocessings** and train a baseline model with the file data_train.csv\n",
    "- **Part 2 :** improve your model's f1-score on your test set (you can try feature engineering, feature selection, regularization, non-linear models, hyperparameter optimization by grid search, etc...)\n",
    "- **Part 3 :** Once you're satisfied with your model's score, you can use it to make some predictions with the file data_test.csv. You will have to dump the predictions into a .csv file that will be sent to Kaggle (actually, to your teacher/TA ü§ì). You can make as many submissions as you want, feel free to try different models !\n",
    "- **Part 4 :** Take some time to analyze your best model's parameters. Are there any lever for action that would help to improve the newsletter's conversion rate ? What recommendations would you make to the team ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcec06-8f8c-4dc9-9a54-4f5673351690",
   "metadata": {},
   "source": [
    "#### Import all library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a5fad4-f347-415e-9a9d-51156dd0c84b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`np.unicode_` was removed in the NumPy 2.0 release. Use `np.str_` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, confusion_matrix\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/plotly/express/__init__.py:27\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mPlotly Express requires numpy to be installed. You can install numpy using pip with:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_imshow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imshow\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chart_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     scatter,\n\u001b[1;32m     30\u001b[0m     scatter_3d,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     density_mapbox,\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     set_mapbox_access_token,\n\u001b[1;32m     73\u001b[0m     defaults,\n\u001b[1;32m     74\u001b[0m     get_trendline_results,\n\u001b[1;32m     75\u001b[0m     NO_COLOR,\n\u001b[1;32m     76\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/plotly/express/_imshow.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_array_to_data_uri\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     xarray_imported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing, tutorial\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     load_dataarray,\n\u001b[1;32m      4\u001b[0m     load_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     save_mfdataset,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mzarr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_zarr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/testing.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m duck_array_ops, formatting, utils\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataArray\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/duck_array_ops.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize_axis_index  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstride_tricks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sliding_window_view  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dask_array_ops, dtypes, nputils\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallelcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_chunked_array_type, is_chunked_array\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpycompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_type, is_duck_dask_array\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/dask_array_ops.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes, nputils\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdask_rolling_wrapper\u001b[39m(moving_func, a, window, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper to apply bottleneck moving window funcs on dask arrays\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/dtypes.py:43\u001b[0m\n\u001b[1;32m     33\u001b[0m NINF \u001b[38;5;241m=\u001b[39m AlwaysLessThan()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Pairs of types that, if both found, should be promoted to object dtype\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# instead of following NumPy's own type-promotion rules. These type promotion\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# rules match pandas instead. For reference, see the NumPy type hierarchy:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# https://numpy.org/doc/stable/reference/arrays.scalars.html\u001b[39;00m\n\u001b[1;32m     40\u001b[0m PROMOTE_TO_OBJECT: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[np\u001b[38;5;241m.\u001b[39mgeneric], \u001b[38;5;28mtype\u001b[39m[np\u001b[38;5;241m.\u001b[39mgeneric]], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m     (np\u001b[38;5;241m.\u001b[39mnumber, np\u001b[38;5;241m.\u001b[39mcharacter),  \u001b[38;5;66;03m# numpy promotes to character\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     (np\u001b[38;5;241m.\u001b[39mbool_, np\u001b[38;5;241m.\u001b[39mcharacter),  \u001b[38;5;66;03m# numpy promotes to character\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     (np\u001b[38;5;241m.\u001b[39mbytes_, np\u001b[38;5;241m.\u001b[39municode_),  \u001b[38;5;66;03m# numpy promotes to unicode\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_promote\u001b[39m(dtype):\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simpler equivalent of pandas.core.common._maybe_promote\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    fill_value : Valid missing value for the promoted dtype.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:778\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __expired_attributes__:\n\u001b[0;32m--> 778\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was removed in the NumPy 2.0 release. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__expired_attributes__[attr]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    781\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     )\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchararray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    785\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`np.chararray` is deprecated and will be removed from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe main namespace in the future. Use an array with a string \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor bytes dtype instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: `np.unicode_` was removed in the NumPy 2.0 release. Use `np.str_` instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template(\n",
    "    layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\", \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"]\n",
    ")\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"svg\" # to be replaced by \"iframe\" if working on JULIE\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b473456-1dbd-4ce8-8fc3-8b59facf821f",
   "metadata": {},
   "source": [
    "#### 1- EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3aa522c-257f-4388-9bf2-01ff3d0ce4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set with labels (our train+test) : (284580, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./conversion_rate/conversion_data_train.csv')\n",
    "print('Set with labels (our train+test) :', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd8b2630-e18d-4d84-890d-e261927a122f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Ads</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Seo</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Seo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  age  new_user  source  total_pages_visited  converted\n",
       "0    China   22         1  Direct                    2          0\n",
       "1       UK   21         1     Ads                    3          0\n",
       "2  Germany   20         0     Seo                   14          1\n",
       "3       US   23         1     Seo                    3          0\n",
       "4       US   28         1  Direct                    3          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736dde86-58bb-4914-bcb8-a1c103f0e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Premi√®res lignes ===\n",
      "   country  age  new_user  source  total_pages_visited  converted\n",
      "0    China   22         1  Direct                    2          0\n",
      "1       UK   21         1     Ads                    3          0\n",
      "2  Germany   20         0     Seo                   14          1\n",
      "3       US   23         1     Seo                    3          0\n",
      "4       US   28         1  Direct                    3          0\n",
      "\n",
      "=== Derni√®res lignes ===\n",
      "       country  age  new_user  source  total_pages_visited  converted\n",
      "284575      US   36         1     Ads                    1          0\n",
      "284576      US   31         1     Seo                    2          0\n",
      "284577      US   41         1     Seo                    5          0\n",
      "284578      US   31         1  Direct                    4          0\n",
      "284579      US   26         0     Ads                    3          0\n",
      "\n",
      "=== Dimensions ===\n",
      "Lignes : 284580\n",
      "Colonnes : 6\n",
      "\n",
      "=== Liste des colonnes ===\n",
      "['country', 'age', 'new_user', 'source', 'total_pages_visited', 'converted']\n",
      "\n",
      "=== Informations g√©n√©rales ===\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 284580 entries, 0 to 284579\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype\n",
      "---  ------               --------------   -----\n",
      " 0   country              284580 non-null  str  \n",
      " 1   age                  284580 non-null  int64\n",
      " 2   new_user             284580 non-null  int64\n",
      " 3   source               284580 non-null  str  \n",
      " 4   total_pages_visited  284580 non-null  int64\n",
      " 5   converted            284580 non-null  int64\n",
      "dtypes: int64(4), str(2)\n",
      "memory usage: 14.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##### Analysons les donn√©es\n",
    "# 1. Voir les premi√®res lignes\n",
    "print(\"=== Premi√®res lignes ===\")\n",
    "print(data.head())\n",
    "\n",
    "# 2. Voir les derni√®res lignes (pour v√©rifier la coh√©rence)\n",
    "print(\"\\n=== Derni√®res lignes ===\")\n",
    "print(data.tail())\n",
    "\n",
    "# 3. Conna√Ætre la taille du dataset\n",
    "print(f\"\\n=== Dimensions ===\")\n",
    "print(f\"Lignes : {data.shape[0]}\")\n",
    "print(f\"Colonnes : {data.shape[1]}\")\n",
    "\n",
    "# 4. Lister toutes les colonnes\n",
    "print(\"\\n=== Liste des colonnes ===\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# 5. Obtenir les infos g√©n√©rales\n",
    "print(\"\\n=== Informations g√©n√©rales ===\")\n",
    "print(data.info())\n",
    "\n",
    "# Nombre de lignes et colonnes : Est-ce que c'est beaucoup ? Peu ?\n",
    "# Noms des colonnes : Sont-ils clairs ? Compr√©hensibles ?\n",
    "# Types de donn√©es : int64, float64, object, datetime ?\n",
    "# Valeurs manquantes : Y a-t-il des \"Non-Null\" diff√©rents du nombre total de lignes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da327e2-902d-41cb-89f4-4e6f12183dc6",
   "metadata": {},
   "source": [
    "#### Analysons les types de variables\n",
    "- Variable categorielle : Nominal: Country, Source\n",
    "- Variable numerique: discr√®te: Age, new_user, total_pages_visited, converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09349ddc-04c4-43b7-be82-698ed0f14e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VARIABLES NUM√âRIQUES ===\n",
      "['age', 'new_user', 'total_pages_visited', 'converted']\n",
      "\n",
      "=== VARIABLES CAT√âGORIELLES ===\n",
      "['country', 'source']\n",
      "\n",
      "=== VARIABLES DATETIME ===\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76242/3158694855.py:8: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  variables_categorielles = data.select_dtypes(include=['object']).columns.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Si necessaires mais pas forcement\n",
    "# √âTAPE 2.1 : S√©parer les variables par type\n",
    "\n",
    "# Variables num√©riques\n",
    "variables_numeriques = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Variables cat√©gorielles (texte/objet)\n",
    "variables_categorielles = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Variables datetime (si pr√©sentes)\n",
    "variables_datetime = data.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "\n",
    "print(\"=== VARIABLES NUM√âRIQUES ===\")\n",
    "print(variables_numeriques)\n",
    "\n",
    "print(\"\\n=== VARIABLES CAT√âGORIELLES ===\")\n",
    "print(variables_categorielles)\n",
    "\n",
    "print(\"\\n=== VARIABLES DATETIME ===\")\n",
    "print(variables_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63559ae0-3f98-4834-bd6d-0bd38a474ba5",
   "metadata": {},
   "source": [
    "#### Analysons les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307a9ce1-b7e5-4c84-84ab-12a1d700546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Colonne, Valeurs_manquantes, Pourcentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# J'ai cr√©√© un dataframe, puis filtrer par des valeurs manquantes positives\n",
    "missing_df = pd.DataFrame({\n",
    "    'Colonne': data.columns,\n",
    "    'Valeurs_manquantes': data.isnull().sum(),\n",
    "    'Pourcentage': (data.isnull().sum() / len(data)) * 100\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Valeurs_manquantes'] > 0].sort_values(\n",
    "    'Pourcentage', ascending=False\n",
    ")\n",
    "\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33baa1d8-d916-487f-82da-3edf99472b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>new_user</th>\n",
       "      <th>source</th>\n",
       "      <th>total_pages_visited</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580</td>\n",
       "      <td>284580.000000</td>\n",
       "      <td>284580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>160124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.564203</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873252</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.266789</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.341995</td>\n",
       "      <td>0.176685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country            age       new_user  source  total_pages_visited  \\\n",
       "count   284580  284580.000000  284580.000000  284580        284580.000000   \n",
       "unique       4            NaN            NaN       3                  NaN   \n",
       "top         US            NaN            NaN     Seo                  NaN   \n",
       "freq    160124            NaN            NaN  139477                  NaN   \n",
       "mean       NaN      30.564203       0.685452     NaN             4.873252   \n",
       "std        NaN       8.266789       0.464336     NaN             3.341995   \n",
       "min        NaN      17.000000       0.000000     NaN             1.000000   \n",
       "25%        NaN      24.000000       0.000000     NaN             2.000000   \n",
       "50%        NaN      30.000000       1.000000     NaN             4.000000   \n",
       "75%        NaN      36.000000       1.000000     NaN             7.000000   \n",
       "max        NaN     123.000000       1.000000     NaN            29.000000   \n",
       "\n",
       "            converted  \n",
       "count   284580.000000  \n",
       "unique            NaN  \n",
       "top               NaN  \n",
       "freq              NaN  \n",
       "mean         0.032258  \n",
       "std          0.176685  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ad383-4f41-41a6-84fb-a8141bd8d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mbola tohizana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca46f07b-e885-429a-bc85-81df72871071",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['total_pages_visited']\n",
    "numeric_indices = [0]\n",
    "categorical_indices = []\n",
    "target_variable = 'converted'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f753675-f02d-427a-ae33-e8a56c98aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanatory variables :  Index(['total_pages_visited'], dtype='str')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, features_list]\n",
    "Y = data.loc[:, target_variable]\n",
    "\n",
    "print('Explanatory variables : ', X.columns)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "976c40ca-62f3-4917-a304-5140a1e824a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set\n",
    "print(\"Dividing into train and test sets...\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "print(\"...Done.\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55cca1be-4529-490b-88c2-621c8896226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[-0.26070136]\n",
      " [ 0.93728655]\n",
      " [-0.85969532]\n",
      " [-0.56019834]\n",
      " [-0.26070136]]\n"
     ]
    }
   ],
   "source": [
    "# Put here all the preprocessings\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "featureencoder = StandardScaler()\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e3c0061-d076-45d4-ad9e-bf6664aea33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression() #\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "458040c6-3a2e-4fd3-9b2f-5eb3b1884244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48e41b48-5535-411b-8d86-0782bdd703f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features and standardizing numerical features...\n",
      "...Done\n",
      "[[ 0.63778957]\n",
      " [ 0.03879562]\n",
      " [-0.26070136]\n",
      " [-0.26070136]\n",
      " [ 0.63778957]]\n"
     ]
    }
   ],
   "source": [
    "# Use X_test, and the same preprocessings as in training pipeline,\n",
    "# but call \"transform()\" instead of \"fit_transform\" methods (see example below)\n",
    "\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6e34245-cc13-418c-8004-63fa46388140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790716e-56b4-4421-a7a3-f5a42420b2b8",
   "metadata": {},
   "source": [
    "### Performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2249955-b065-4f87-82a1-be92767b5571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on train set :  0.6938517686692869\n",
      "f1-score on test set :  0.7060240963855422\n"
     ]
    }
   ],
   "source": [
    "# WARNING : Use the same score as the one that will be used by Kaggle !\n",
    "# Here, the f1-score will be used to assess the performances on the leaderboard\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03437bb9-e72c-4d95-ba8c-ca02e8dda74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on train set : \n",
      "[[246817   1082]\n",
      " [  3280   4943]]\n",
      "\n",
      "Confusion matrix on test set : \n",
      "[[27384   117]\n",
      " [  371   586]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also check more performance metrics to better understand what your model is doing\n",
    "print(\"Confusion matrix on train set : \")\n",
    "print(confusion_matrix(Y_train, Y_train_pred))\n",
    "print()\n",
    "print(\"Confusion matrix on test set : \")\n",
    "print(confusion_matrix(Y_test, Y_test_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059b08a-e133-478b-a25a-12a7cade5914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
