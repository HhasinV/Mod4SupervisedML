





import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import warnings

warnings.filterwarnings(
    "ignore", category=DeprecationWarning
)  
print("good")


df = pd.read_csv("titanic.csv")






row = df.shape[0]
print(f"Le nombre des lignes est de {row}")

df.head()



# determinons les diiferentes caract des données
df.describe(include='all').T


# Percentage o.f missing values:
df.isna().sum()


# Normaliser
(df.isna().sum() / df.shape[0])*100





#Les colonnes qui possèdent tout le temps les même valeurs ne me servent à rien 
# Les colonnes qui possèdent trop de valeurs uniques qualitatives ne me servent à rien dans le contexte du machine learning.
# passengerId, name, Ticket
column_to_drop = ["PassengerId","Name","Ticket"]
df = df.drop(
    column_to_drop, axis=1 
)




df = df.drop(
    ['Cabin'], axis=1 
)
df.head()











# Separate target variable Y from features X
target_name = 'Survived'

print("Separating labels from features...")
Y = df.loc[:,target_name]
X = df.drop(target_name, axis = 1)
print("...Done.")
print(Y.head())
print()
print(X.head())
print()




# Separer les données
print("Dividing into train and test sets...")
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=0)
print("Done")


X_train.head()





# Create pipeline for numeric features
# Numerique: StandardScaler rehefa qualitative
numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'] # Names of numeric columns in X_train/X_test
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')), # missing values in Age will be replaced by columns' mean
    ('scaler', StandardScaler())
])

# StandardScaler: StandardScaler
# StandardScaler est un outil de scikit-learn qui normalise les données numériques en les transformant pour avoir :
# Moyenne = 0
# Écart-type = 1
# Mba ho meme ordre de grandeur , meme , ramene à l'echelle
# type regression: modele tres sensible à la ordre grandeur








# Qualitative:OneHotEncoder
# Create pipeline for categorical features
categorical_features = ['Sex', 'Embarked'] # Names of categorical columns in X_train/X_test
categorical_transformer = Pipeline(
    steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value
    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features
    ])

# Manambotra ilay sparse matrice, ngezaa be io








# Use ColumnTranformer to make a preprocessor object that describes all the treatments to be done
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Preprocessings on train set
print("Performing preprocessings on train set...")
print(X_train.head())
X_train = preprocessor.fit_transform(X_train)
print('...Done.')
print(X_train[0:5,:])
print()

# Preprocessings on test set
print("Performing preprocessings on test set...")
print(X_test.head())
X_test = preprocessor.transform(X_test) # Don't fit again !!
print('...Done.')
print(X_test[0:5,:])
print()









from sklearn.linear_model import LogisticRegression


# Train model
# Probleme de classification: regression logistique
model = LogisticRegression()

print("Training model...")
model.fit(X_train, Y_train) # Training is always done on train set !!
print("...Done.")





# Predictions on training set
print("Predictions on training set...")
Y_train_pred = model.predict(X_train)
print("...Done.")
print(Y_train_pred[0:5])
print()


# Predictions on test set
print("Predictions on test set...")
Y_test_pred = model.predict(X_test)
print("...Done.")
print(Y_test_pred[0:5])
print()





from sklearn.metrics import accuracy_score


# Print scores
print("Accuracy on training set : ", accuracy_score(Y_train, Y_train_pred))
print("Accuracy on test set : ", accuracy_score(Y_test, Y_test_pred))



